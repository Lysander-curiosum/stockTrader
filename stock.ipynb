{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508d442e",
   "metadata": {},
   "source": [
    "## Plutus\n",
    "A simple classifier which aims to identify stocks currently on a \"bullish\" trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce86b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "['A' 'AA' 'AAC' ... 'ZYME' 'ZYNE' 'ZYXI']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# the greek god of wealth (son of Iason and Demeter)\n",
    "# dependencies\n",
    "\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for loading data\n",
    "from scipy.io import loadmat\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# api keys\n",
    "api = tradeapi.REST(\n",
    "        'AKUGANQEC0256T5OKJJA',\n",
    "        'LNPrnn2jpq8HTRb86xv7jeEfV4qPxJbJz18IozgD',\n",
    "        'https://api.alpaca.markets',\n",
    "        api_version = 'v2')\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "\n",
    "# nasdaq tickers\n",
    "# can add from other exchanges\n",
    "nasdaq = pd.read_csv('nasdaq.csv', sep=',', low_memory=False)\n",
    "tickers = np.array(nasdaq['Symbol'])\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ff4e2",
   "metadata": {},
   "source": [
    "## Purchase classifier\n",
    "The aim of this section is to identify stocks which are viable for purchase, meaning that they are currently on a bullish trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a869ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# getData\n",
    "# String -> [int]\n",
    "# The purpose of getData is to build the predictors to train our\n",
    "# classifier. It will return the above data for the given ticker.\n",
    "def getData(ticker):\n",
    "    predictor = []\n",
    "    barset = api.get_barset(ticker, 'day', limit=10)\n",
    "    bars = barset[ticker]\n",
    "    if(len(bars) != 10):\n",
    "        return None\n",
    "    # append the last ten closing prices as features\n",
    "    for x in range(10):\n",
    "        predictor.append(bars[x].c/bars[0].c)\n",
    "    predictor = predictor\n",
    "    # append the last ten volumes as features\n",
    "    for y in range(10):\n",
    "        predictor.append(bars[y].v/bars[0].v)\n",
    "    #toReturn = np.array(predictor)\n",
    "    return predictor\n",
    "\n",
    "# call to get the volume data\n",
    "\n",
    "#classifyData\n",
    "# [float] -> int \n",
    "# classifyData is passed a set of features (a predictor) \n",
    "# and classifies the data point as profitable (purchase)\n",
    "# or not profitable. In essence, we want to confirm that \n",
    "# drawbacks in price (if a closing price is less than the previous day)\n",
    "# are increasingly high (so, the stock is still on a positive trajectory) <-- is the sample size too small?\n",
    "# and that the volume trend confirms the price trend (volume is generally increasing?)\n",
    "\n",
    "# the thing is, we don't want the neural network to learn\n",
    "# our basic, scuffed up function\n",
    "# we want it to identify patterns of its own\n",
    "def classifyData(predictor):\n",
    "    # we begin with the assumption of profitability\n",
    "    profitable = True\n",
    "    # move through the closing prices\n",
    "    # of the stock\n",
    "\n",
    "    # we are going to go with higher lows (in terms of drawbacks)\n",
    "    \n",
    "    # so first, we identify the first drawback in price (if it exists in the 10-day span)\n",
    "    for x in range(10):\n",
    "        if(x > 0):\n",
    "            if(predictor[x] < predictor[x - 1]):\n",
    "                low = predictor[x]\n",
    "                # exit the loop\n",
    "                break\n",
    "    # if we make it through the loop without a drawback\n",
    "    # then, profitable does not become False\n",
    "    for x in range(10):\n",
    "        if(x > 0):\n",
    "            if(predictor[x] < predictor[x - 1]):\n",
    "                if(predictor[x] < low):\n",
    "                    profitable = False\n",
    "                    break\n",
    "                else:\n",
    "                    # else, we keep moving through the list, \n",
    "                    # with the new drawback set as the low\n",
    "                    low = predictor[x]\n",
    "    # now, the volume requirements:\n",
    "    # if it has made it past this point, then the price is on a bullish trend\n",
    "    # volume has to \"confirm\" the trend\n",
    "    # \"higher highs\" and \"lower lows\"\n",
    "    p = 10\n",
    "    while(p < 20):\n",
    "        if(p > 10):\n",
    "            if(predictor[p] < predictor[p - 1]):\n",
    "                volLow = predictor[x]\n",
    "                # exit the loop\n",
    "                break\n",
    "        p+=1\n",
    "    u = 10\n",
    "    while(u < 20):\n",
    "        if(x > 0):\n",
    "            if(predictor[x] < predictor[x - 1]):\n",
    "                # it means the volume is not hitting a \"higher high\"\n",
    "                if(predictor[x] < volLow):\n",
    "                    profitable = False\n",
    "                    break\n",
    "                else:\n",
    "                    # else, we keep moving through the list, \n",
    "                    # with the new drawback set as the low\n",
    "                    volLow = predictor[x]\n",
    "        u+=1\n",
    "    return profitable\n",
    "\n",
    "\n",
    "# build the training data for the classifier\n",
    "def buildData(tickers):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for ticker in tickers:\n",
    "        if(getData(ticker) != None):\n",
    "            toAdd = getData(ticker)\n",
    "            x_data.append(toAdd)\n",
    "            if(classifyData(toAdd)): \n",
    "                # will be a profitable stock\n",
    "                y_data.append(1)\n",
    "            else:\n",
    "                # won't be a profitable stock\n",
    "                y_data.append(0)\n",
    "        else:\n",
    "            # we do nothing\n",
    "            continue\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d542573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab 100 random tickers\n",
    "names = []\n",
    "while(len(names) < 100):\n",
    "    value = randint(0, len(tickers)  - 1)\n",
    "    if(not(tickers[value] in names)):\n",
    "       names.append(tickers[value])\n",
    "    \n",
    "# now, for test data, random batch of 30 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d879eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = buildData(names)\n",
    "#x_test, y_test = builData(tickers[201:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5bc4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = []\n",
    "while(len(test_names) < 30):\n",
    "    value = randint(0, len(tickers) - 1)\n",
    "    if(not(tickers[value] in names) and not(tickers[value] in test_names)):\n",
    "        test_names.append(tickers[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d089bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = buildData(test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "478fa7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "20\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(len(x_test[0]))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "452f4961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "94\n",
      "27\n",
      "27\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "\n",
    "print(y_train)\n",
    "# this shit imbalanced\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97d4eb",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "Here we start the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e10bb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "# (A simple feed foward network)\n",
    "\n",
    "# network will use binary classification, either \"habitable\" or not\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_size, activations):\n",
    "        super().__init__()\n",
    "        assert len(hidden_size) > 0\n",
    "        # valid activation functions to choose from\n",
    "        # can the activations affect the classification in an imbalanced dataset\n",
    "        act = {'sigmoid': nn.Sigmoid(), 'tanh': nn.Tanh(), 'relu': nn.ReLU(),'identity': nn.Identity()}\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(n_layers - 1):\n",
    "            # hidden size i will be number of input neurons'\n",
    "            # hidden size i + 1 will be number of neurons to send signals to\n",
    "            self.layers.append(nn.Linear(hidden_size[i], hidden_size[i + 1]))\n",
    "            \n",
    "            # if activations[i] in act, meaning if its a valid activation function that\n",
    "            # we are looking for\n",
    "            if activations[i] in act:\n",
    "                self.layers.append(act[activations[i]])\n",
    "            else:\n",
    "                assert activations in ['sigmoid', 'tanh', 'relu', 'identity']\n",
    "                \n",
    "            # the activation will be the last layer, the output layer on top of the\n",
    "            # initial n-1 layers\n",
    "            # that is why the ouput is \"2\"\n",
    "            # should be able to have the features reduced into one neuron though, correct?\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for idx in range(len(self.layers) - 1):\n",
    "            x = self.layers[idx](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97f9688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, n_epoch, data, label):\n",
    "    # signals floor division\n",
    "    print_iteration = n_epoch//5\n",
    "    \n",
    "    # data will be the x_training data as a tensor\n",
    "    data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "    \n",
    "    # label will be the y_training data as a tensor\n",
    "    label = torch.tensor(label, dtype=torch.long).squeeze().to(device)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        predict = model(data)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # the loss function should be tuned\n",
    "        loss = criterion(predict, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%print_iteration == 0:\n",
    "        print('epoch: ', epoch, '\\tloss: ', loss.item())\n",
    "        \n",
    "    print('epoch: ', epoch, '\\tloss: ', loss.item())\n",
    "    return model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b43d428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(data, label):\n",
    "    data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "    predict = model(data)\n",
    "    predict = torch.argmax(predict, dim=-1).cpu().detach().numpy()\n",
    "    acc = accuracy_score(predict, label)\n",
    "    return acc, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2cc68537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Setting -------------------\n",
      "hidden layer = 1, neuron = 11\n",
      "--------------- Training -------------------\n",
      "epoch:  999 \tloss:  0.016864916309714317\n",
      "Train Accuracy:  (1.0, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]))\n",
      "--------------- Testing -------------------\n",
      "Test Accuracy:  (0.9629629629629629, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# want to train the network using different assortments of settings\n",
    "settings = {'hidden layer = 1, neuron = 11': {'hs': [20, 20, 2], 'act': ['relu','relu','sigmoid']}}\n",
    "\n",
    "for setting in settings:\n",
    "    print('---------------- Setting -------------------')\n",
    "    print(setting) \n",
    "    n_layers = len(settings[setting]['hs'])\n",
    "    hidden_size = settings[setting]['hs']\n",
    "    activations = settings[setting]['act']\n",
    "    model = NN(n_layers, hidden_size, activations).to(device)\n",
    "    #change for imbalanced data \n",
    "    #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.Adadelta(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.MSELoss()\n",
    "    print('--------------- Training -------------------')\n",
    "    param = train(model, optimizer, criterion, n_epoch, x_train, y_train)\n",
    "    print('Train Accuracy: ', model_accuracy(x_train, y_train))\n",
    "    print('--------------- Testing -------------------')\n",
    "    accuracy, predict = model_accuracy(x_test, y_test)\n",
    "    print('Test Accuracy: ', model_accuracy(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "61845c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7991, -4.6675]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Lets test for tesla\n",
    "\n",
    "\n",
    "testa = []\n",
    "testa.append('TSLA')\n",
    "\n",
    "tsla_test_x, tsla_test_y = buildData(testa)\n",
    "\n",
    "\n",
    "data = torch.tensor(tsla_test_x, dtype=torch.float).to(device)\n",
    "#print(tsla_test_y)\n",
    "prediction = model(data)\n",
    "\n",
    "# what does this mean\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec200c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117aca4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
