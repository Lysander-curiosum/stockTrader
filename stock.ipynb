{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508d442e",
   "metadata": {},
   "source": [
    "## Plutus\n",
    "A simple classifier which aims to identify stocks currently on a \"bullish\" trend.\n",
    "\n",
    "An integral part of the eventual application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce86b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "['A' 'AA' 'AAC' ... 'ZYME' 'ZYNE' 'ZYXI']\n"
     ]
    }
   ],
   "source": [
    "# the greek god of wealth (son of Iason and Demeter)\n",
    "\n",
    "# dependencies\n",
    "\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# for loading data\n",
    "from scipy.io import loadmat\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# api keys\n",
    "api = tradeapi.REST(\n",
    "        'AKUGANQEC0256T5OKJJA',\n",
    "        'LNPrnn2jpq8HTRb86xv7jeEfV4qPxJbJz18IozgD',\n",
    "        'https://api.alpaca.markets',\n",
    "        api_version = 'v2')\n",
    "\n",
    "# paper api\n",
    "paper_api = tradeapi.REST('PKDKAO1JPMSFI86UKWW0',\n",
    "        '5L1EmPdcDFMalPtLCgqizoJ5agAFYOrh6Z6MGXUU',\n",
    "        'https://paper-api.alpaca.markets',\n",
    "        api_version = 'v2')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "\n",
    "# nasdaq tickers\n",
    "# can add from other exchanges\n",
    "nasdaq = pd.read_csv('nasdaq.csv', sep=',', low_memory=False)\n",
    "official_ticks = np.array(nasdaq['Symbol'])\n",
    "print(official_ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2aab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "account = api.get_account()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ff4e2",
   "metadata": {},
   "source": [
    "## Purchase classifier\n",
    "The aim of this section is to identify stocks which are viable for purchase, meaning that they are currently on a bullish trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a869ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# getData\n",
    "# String -> [int]\n",
    "# The purpose of getData is to build the predictors to train our\n",
    "# classifier. It will return the above data for the given ticker.\n",
    "def getData(ticker, days):\n",
    "    predictor = []\n",
    "    try:\n",
    "        barset = api.get_barset(ticker, 'day', limit=days)\n",
    "    except (requests.HTTPError, ValueError):\n",
    "        print(\"Invalid entry\")\n",
    "        return None\n",
    "    bars = barset[ticker]\n",
    "    if(len(bars) != days):\n",
    "        return None\n",
    "    # append the last ten closing prices as features\n",
    "    for x in range(days):\n",
    "        #predictor.append(bars[x].c/bars[0].c)\n",
    "        predictor.append(bars[x].c)\n",
    "    predictor = predictor\n",
    "    # append the last ten volumes as features\n",
    "    for y in range(days):\n",
    "        #predictor.append(bars[y].v/bars[0].v)\n",
    "        predictor.append(bars[y].v)\n",
    "    #toReturn = np.array(predictor)\n",
    "    return predictor\n",
    "\n",
    "# call to get the volume data\n",
    "\n",
    "#classifyData\n",
    "# [float] -> int \n",
    "# classifyData is passed a set of features (a predictor) \n",
    "# and classifies the data point as profitable (purchase)\n",
    "# or not profitable. In essence, we want to confirm that \n",
    "# drawbacks in price (if a closing price is less than the previous day)\n",
    "# are increasingly high (so, the stock is still on a positive trajectory) <-- is the sample size too small?\n",
    "# and that the volume trend confirms the price trend (volume is generally increasing?)\n",
    "\n",
    "# the thing is, we don't want the neural network to learn\n",
    "# our basic, scuffed up function\n",
    "# we want it to identify patterns of its own\n",
    "\n",
    "# what patterns indicate a good purchase point?\n",
    "# these patterns indicate a positive momentum trend\n",
    "# so we would want to train the classifier on the 5 day data from before this trend beginning?\n",
    "\n",
    "# however, we want to make sure that we are not purchasing at the turn of a stock, at a reversal\n",
    "def classifyData(predictor, days):\n",
    "    volLow = predictor[days]\n",
    "    # set the low to first value\n",
    "    low = predictor[0]\n",
    "    # we begin with the assumption of profitability\n",
    "    profitable = True\n",
    "    # move through the closing prices\n",
    "    # of the stock\n",
    "\n",
    "    # we are going to go with higher lows (in terms of drawbacks)\n",
    "    for x in range(1, days):\n",
    "        if(predictor[x] < predictor[x - 1]):\n",
    "            # initial low\n",
    "            low = predictor[x]\n",
    "            # exit the loop\n",
    "            break\n",
    "    \n",
    "    # if we make it through the loop without a drawback\n",
    "    # then, profitable does not become False\n",
    "    for h in range(1, days):\n",
    "        if(predictor[h] < predictor[h - 1]):\n",
    "            if(predictor[h] < low):\n",
    "                # only update if lower low is reached\n",
    "                profitable = False\n",
    "                break\n",
    "            else:\n",
    "                # else, we keep moving through the list, \n",
    "                # with the new drawback set as the low\n",
    "                low = predictor[x]\n",
    "                    \n",
    "    # what volume trend would \"confirm\" the shape of the data\n",
    "    \n",
    "    # now, the volume requirements:\n",
    "    # if it has made it past this point, then the price is on a bullish trend\n",
    "    # volume has to \"confirm\" the trend\n",
    "    # \"higher highs\" and \"lower lows\"\n",
    "    p = days\n",
    "    while(p < days * 2):\n",
    "        if(predictor[p] < predictor[p - 1]):\n",
    "            volLow = predictor[p]\n",
    "            # exit the loop\n",
    "            break\n",
    "        p+=1\n",
    "\n",
    "    u = days\n",
    "    while(u < days * 2):\n",
    "        if(predictor[u] < predictor[u - 1]):\n",
    "            # it means the volume is not hitting a \"higher high\"\n",
    "            if(predictor[u] < volLow):\n",
    "                profitable = False\n",
    "                break\n",
    "            else:\n",
    "                # else, we keep moving through the list, \n",
    "                # with the new drawback set as the low\n",
    "                volLow = predictor[u]\n",
    "        u+=1\n",
    "    \n",
    "    return profitable\n",
    "\n",
    "# just to test the viability of the classifier (returns true if the price has increased)\n",
    "def simpClassifyData(predictor):\n",
    "    if(predictor[0] < predictor[9]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# build the training data for the classifier\n",
    "def buildData(tickers, days):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for ticker in tickers:\n",
    "        if(getData(ticker) != None):\n",
    "            toAdd = getData(ticker, 5)\n",
    "            # perhaps we append the 5-day data from before \n",
    "            # the ten day period that we are measuring\n",
    "            x_data.append(toAdd)\n",
    "            if(classifyData(toAdd, 5)): \n",
    "                # will be a profitable stock\n",
    "                y_data.append(1)\n",
    "            else:\n",
    "                # won't be a profitable stock\n",
    "                y_data.append(0)\n",
    "        else:\n",
    "            # we do nothing\n",
    "            continue\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e827fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372.9\n",
      "[3419.77, 3393.71, 3413.22, 3383.01, 3372.9, 1623081, 2585900, 2476523, 1582459, 1671897]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "\n",
    "ay = getData('AMZN')\n",
    "print(ay[4])\n",
    "print(ay)\n",
    "\n",
    "otay = classifyData(ay)\n",
    "print(otay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d542573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab 100 random tickers\n",
    "names = []\n",
    "# so there is a maximum number of api calls\n",
    "while(len(names) < 100):\n",
    "    value = randint(0, len(official_ticks)  - 1)\n",
    "    if(not(official_ticks[value] in names)):\n",
    "       names.append(official_ticks[value])\n",
    "\n",
    "# now, for test data, random batch of 30 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d879eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = buildData(names, 5)\n",
    "#x_test, y_test = builData(tickers[201:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5bc4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = []\n",
    "while(len(test_names) < 75):\n",
    "    value = randint(0, len(official_ticks) - 1)\n",
    "    if(not(official_ticks[value] in names) and not(official_ticks[value] in test_names)):\n",
    "        test_names.append(official_ticks[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d089bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = buildData(test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf3014",
   "metadata": {},
   "source": [
    "## Further pre-processing\n",
    "To center the predictor variables (training data, test data) one could divide all of the values by the average feature values (how to get the average feature?) and/or dividing each feature value by its standard deviation.\n",
    "\n",
    "\n",
    "Dimensionality reduction? (principle component analysis?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d23037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452f4961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "93\n",
      "73\n",
      "73\n",
      "[1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# check data\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "\n",
    "print(y_train)\n",
    "# this shit imbalanced\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97d4eb",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "Here we start the classifier.\n",
    "\n",
    "\n",
    "How to refine to best fit the data?\n",
    "\n",
    "To understand:\n",
    "    - How are the weights initialized? (pytorch uses Xavier initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e10bb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "# (A simple feed foward network)\n",
    "\n",
    "# refine\n",
    "\n",
    "# REFINE THE MODEL\n",
    "# add some \"twists\" based on your more \"intimiate\" understanding of what a neural network is, and\n",
    "# how it can be applied to this problem\n",
    "\n",
    "# network will use binary classification, either \"habitable\" or not\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_size, activations):\n",
    "        super().__init__()\n",
    "        assert len(hidden_size) > 0\n",
    "        # valid activation functions to choose from\n",
    "        # can the activations affect the classification in an imbalanced dataset\n",
    "        act = {'sigmoid': nn.Sigmoid(), 'tanh': nn.Tanh(), 'relu': nn.ReLU(),'identity': nn.Identity()}\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(n_layers - 1):\n",
    "            # hidden size i will be number of input neurons'\n",
    "            # hidden size i + 1 will be number of neurons to send signals to\n",
    "            self.layers.append(nn.Linear(hidden_size[i], hidden_size[i + 1]))\n",
    "            \n",
    "            # if activations[i] in act, meaning if its a valid activation function that\n",
    "            # we are looking for\n",
    "            if activations[i] in act:\n",
    "                self.layers.append(act[activations[i]])\n",
    "            else:\n",
    "                assert activations in ['sigmoid', 'tanh', 'relu', 'identity']\n",
    "                \n",
    "            # how does pytorch even work my boy\n",
    "            #self.layers.append('sigmoid')\n",
    "        #self.layers.append(nn.Linear(hidden_size[n_layers - 2], 1))\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "    # an iteration of the neural network\n",
    "    def forward(self, x):\n",
    "        for idx in range(len(self.layers) - 1):\n",
    "            x = self.layers[idx](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f9688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, n_epoch, data, label):\n",
    "    # signals floor division\n",
    "    print_iteration = n_epoch//5\n",
    "    \n",
    "    # data will be the x_training data as a tensor\n",
    "    data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "    \n",
    "    # label will be the y_training data as a tensor\n",
    "    label = torch.tensor(label, dtype=torch.long).squeeze().to(device)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        predict = model(data)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # the loss function should be tuned\n",
    "        loss = criterion(predict, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%print_iteration == 0:\n",
    "        print('epoch: ', epoch, '\\tloss: ', loss.item())\n",
    "        \n",
    "    print('epoch: ', epoch, '\\tloss: ', loss.item())\n",
    "    return model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b43d428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(data, label):\n",
    "    data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "    predict = model(data)\n",
    "    \n",
    "    # argmax? so it takes the maximum arguement of a dimensionality reduction?\n",
    "    # what math is happening?\n",
    "    predict = torch.argmax(predict, dim=-1).cpu().detach().numpy()\n",
    "    acc = accuracy_score(predict, label)\n",
    "    return acc, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc68537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Network -------------------\n",
      "n1\n",
      "--------------- Training -------------------\n",
      "epoch:  999 \tloss:  0.3395290970802307\n",
      "Train Accuracy:  (0.946236559139785, array([1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0]))\n",
      "--------------- Testing -------------------\n",
      "Test Accuracy:  (0.7534246575342466, array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "       0, 0, 0, 1, 0, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# put this in the main function\n",
    "# do we want to train it from scratch at each subsequent call?\n",
    "# how do we continually refine w/ new data? preserve the state of the model\n",
    "\n",
    "n_epoch = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# want the network to be hundred percent accurate\n",
    "\n",
    "# want to train the network using different assortments of settings\n",
    "settings = {'n1': {'hs': [10, 10, 10, 10, 2], 'act': ['relu','relu','relu','sigmoid']}}\n",
    "\n",
    "\n",
    "# we want 100 percent accuracy\n",
    "for setting in settings:\n",
    "    print('---------------- Network -------------------')\n",
    "    print(setting) \n",
    "    n_layers = len(settings[setting]['hs'])\n",
    "    hidden_size = settings[setting]['hs']\n",
    "    activations = settings[setting]['act']\n",
    "    \n",
    "    model = NN(n_layers, hidden_size, activations).to(device)\n",
    "    \n",
    "    #change for imbalanced data \n",
    "    # what is the optimizer ?\n",
    "    \n",
    "    # goal: make the model more accurate\n",
    "    # what should we refine?\n",
    "    \n",
    "    #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.Adadelta(model.parameters())\n",
    "    \n",
    "    # class weights\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.MSELoss()\n",
    "    print('--------------- Training -------------------')\n",
    "    param = train(model, optimizer, criterion, n_epoch, x_train, y_train)\n",
    "    print('Train Accuracy: ', model_accuracy(x_train, y_train))\n",
    "    print('--------------- Testing -------------------')\n",
    "    accuracy, predict = model_accuracy(x_test, y_test)\n",
    "    print('Test Accuracy: ', model_accuracy(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61845c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# findPurchase\n",
    "# [String] -> String\n",
    "# findPurchase takes in a list of tickers, and iterates through them\n",
    "# until the model reccomends one for purchase. It will return the name of the first valid ticker\n",
    "# to be purchased.\n",
    "def findPurchase(tickers):\n",
    "    for ticker in tickers:\n",
    "        well = []\n",
    "        well.append(ticker)\n",
    "        x, y = buildData(well)\n",
    "        \n",
    "        # meaning, the dataset is not valid\n",
    "        # will not work in creating a prediction\n",
    "        if(len(x) != 10):\n",
    "            continue\n",
    "        data = torch.tensor(x, dtype=torch.float).to(device)\n",
    "        prediction = model(data)\n",
    "        \n",
    "        # what does this reduction actually do\n",
    "        predict = torch.argmax(prediction, dim=-1).numpy()\n",
    "        \n",
    "        # this returns the first ticker identified for sale\n",
    "        if(predict == 1):\n",
    "            return ticker\n",
    "    print(\"No valid tickers\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0d73457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v1/bars/day 3 more time(s)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r0/_3y3kj9d09350r_smmnsxfqw0000gn/T/ipykernel_1097/1926786570.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test for findPurchase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfindPurchase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofficial_ticks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(official_ticks[:50])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/r0/_3y3kj9d09350r_smmnsxfqw0000gn/T/ipykernel_1097/1291128064.py\u001b[0m in \u001b[0;36mfindPurchase\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mwell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# meaning, the dataset is not valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/r0/_3y3kj9d09350r_smmnsxfqw0000gn/T/ipykernel_1097/1142780938.py\u001b[0m in \u001b[0;36mbuildData\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mtoAdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# perhaps we append the 5-day data from before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/r0/_3y3kj9d09350r_smmnsxfqw0000gn/T/ipykernel_1097/1142780938.py\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mbarset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_barset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid entry\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/alpaca_trade_api/rest.py\u001b[0m in \u001b[0;36mget_barset\u001b[0;34m(self, symbols, timeframe, limit, start, end, after, until)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muntil\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'until'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/bars/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBarSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/alpaca_trade_api/rest.py\u001b[0m in \u001b[0;36mdata_get\u001b[0;34m(self, path, data, api_version)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mbase_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         )\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/alpaca_trade_api/rest.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, path, data, base_url, api_version)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRetryException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mretry_wait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/alpaca_trade_api/rest.py\u001b[0m in \u001b[0;36m_one_request\u001b[0;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[1;32m    207\u001b[0m         \u001b[0mretry_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry_codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stocked/venv/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test for findPurchase\n",
    "\n",
    "# subscription to Alpaca premium: 9$ a month\n",
    "# perhaps worth it?\n",
    "# i need a source of reliable data\n",
    "\n",
    "# perhaps we would be better off using a random number generator\n",
    "# because we can make limited calls to the api for stock information\n",
    "findPurchase(official_ticks[:200])\n",
    "#print(official_ticks[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64870b",
   "metadata": {},
   "source": [
    "## Purchase\n",
    "Here, we make the actual aquisition of the stock. Based on the model that has already been train, we simply make the call to findPurchase, which will select a stock based on our requirements and buy it.\n",
    "\n",
    "(In order to make the process fully automated, we put the whole file into google cloud scheduler, and then create a main function to run it?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buy\n",
    "# void -> void\n",
    "# The purpose of this function is to execute the purchase of a desired stock. In terms of the proportion of my\n",
    "# portfolio that I am willing to invest, I shall begin with a base 5 percent for each purchase\n",
    "\n",
    "# make this dynamic? (i.e, how to adjust the size of the purchase?)\n",
    "# we need a more detailed classifier, with perhaps more classes\n",
    "# a confidence scale, if you will, based on the possible strength in the trend\n",
    "# The network could predict the price increase, for instance (Hmmmmmm)\n",
    "# or just an extremely accurate price prediction (trend prediction is far more viable, and valuable)\n",
    "\n",
    "def buy():\n",
    "    # find the ticker to buy\n",
    "    to_buy = findPurchase(official_ticks)\n",
    "    # then, make the call to the Alpaca API to make a purchase (10 percent of portfolio?)\n",
    "    purchase_power = account.buyingpower\n",
    "    \n",
    "    amount = purchase_power * 0.05\n",
    "    \n",
    "    last_price = api.get_last_quote(to_buy)\n",
    "    \n",
    "    api.submit_order(\n",
    "        symbol=to_buy,\n",
    "        qty=amount/last_price,\n",
    "        side='buy',\n",
    "        type='market',\n",
    "        time_in_force='gtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the automated trade\n",
    "\n",
    "# in terms of training our classifier, the classifyData function\n",
    "# will need to be tuned the most\n",
    "\n",
    "\n",
    "# how many times wwill we run this? Purchase on multiple tickers?\n",
    "# have to iron this out in the actual calls to the trader\n",
    "buy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4a9b3f",
   "metadata": {},
   "source": [
    "## Sell\n",
    "In this segment, the classifier will decide when to sell.\n",
    "(Track current portfolio? Based on stocks being tracked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d86e5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSLA', 'PLTR', 'AMZN', 'AAPL']\n"
     ]
    }
   ],
   "source": [
    "# a second model\n",
    "# an SVM?\n",
    "# simple logistic regression?\n",
    "\n",
    "# first, we would want to get our positions\n",
    "my_pos = paper_api.list_positions()\n",
    "pos_df = pd.DataFrame(positions)\n",
    "\n",
    "\n",
    "# getSymbols\n",
    "# df? (what is that) -> [String]\n",
    "# parameters: \n",
    "# positions (all of the information on current assets associated w/ the current account)\n",
    "# getSymbols returns a list of all the symbols invested that are associated with the current\n",
    "# account \n",
    "\n",
    "def getSymbols(positions):\n",
    "    myticks = []\n",
    "    p = 0\n",
    "    while(p < len(positions)):\n",
    "        myticks.append(positions[p].symbol)\n",
    "        p += 1\n",
    "    return myticks\n",
    "\n",
    "\n",
    "uh = getSymbols(my_pos)\n",
    "\n",
    "print(uh)\n",
    "\n",
    "# how to have a list of tickers?\n",
    "# how to find a sell point\n",
    "\n",
    "# classifier:\n",
    "# we want to train a classifier to make the identification automatically\n",
    "# 10 day data on reversals?\n",
    "# do we want to slowly build this identification ourselves? Or use some sort of preprocessed database?\n",
    "\n",
    "# reversal\n",
    "# a lower low than the previous pullback?\n",
    "\n",
    "\n",
    "# For the classifier, we first need to build the dataset\n",
    "# so, we will try to identify if a reversal is about to take place\n",
    "# for as many api calls as possible\n",
    "\n",
    "# reversalSimple\n",
    "# String -> Boolean\n",
    "# parameters:\n",
    "# ticker is the symbol that we will identify as on the verge of a reversal or not.\n",
    "# In this simple function, we will look for a \"head and shoulders\" reversal\n",
    "# 1.) prior uptrend\n",
    "# 2.) Left shoulder on heavier volume\n",
    "# 3.) rally to new highs on lighter volume\n",
    "# 4.) Decline that moves below previous peak, approaches previous reaction low\n",
    "# 5.) Third rally on noticeably light volume that fails to reach the top of the head\n",
    "# 6.) A close below the neckline\n",
    "# 7.) Return move to the neckline followed by lower lows\n",
    "# At this point, is it already too late? We have lost the peak\n",
    "def reversalSimple(ticker):\n",
    "    try:\n",
    "        # build data over 10 day period, for reversal classification\n",
    "        toTrack = getData(ticker, 10)\n",
    "    except (requests.HTTPError, ValueError):\n",
    "        print(\"Invalid entry\")\n",
    "        return None\n",
    "    \n",
    "    # so for the trend to begin, there first needs to be a prior uptrend\n",
    "    # Perhaps, we shall simply say in the first 5 days of the momentum swing?\n",
    "    # 1/2 ()\n",
    "    \n",
    "    # check uptrend, in the first 5 days\n",
    "    toCheck = toTrack[:5]\n",
    "    toCheck.concat(toTrack[10:15])\n",
    "\n",
    "    uptrend = classifyData(toCheck, 5)\n",
    "    if(not(uptrend)):\n",
    "        return False\n",
    "    \n",
    "    # if there was a prior uptrend in the previous 5 days, on the 7th day, there\n",
    "    # should be new high on light volume\n",
    "    \n",
    "    if((toTrack[6] > toTrack[4]) and (toTrack[16] < toTrack[14])):\n",
    "        print(\"possible reversal\")\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    # then, decline moves below previous peak, and rally with lighter volume than previous volume peak\n",
    "    if((toTrack[7] < toTrack[6]) and ((toTrack[8] > toTrack[7]) and (toTrack[18] < toTrack[16]))):\n",
    "        return True\n",
    "    \n",
    "    # the last day is irrelevant. \n",
    "    \n",
    "    # will automatically return False\n",
    "    return False\n",
    "\n",
    "\n",
    "# build the training data for the classifier\n",
    "def buildData_sell(tickers, days):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for ticker in tickers:\n",
    "        if(getData(ticker, days) != None):\n",
    "            toAdd = getData(ticker, days)\n",
    "            # perhaps we append the 5-day data from before \n",
    "            # the ten day period that we are measuring\n",
    "            x_data.append(toAdd)\n",
    "            if(reversalSimple(ticker)): \n",
    "                # will be a profitable stock\n",
    "                y_data.append(1)\n",
    "            else:\n",
    "                # won't be a profitable stock\n",
    "                y_data.append(0)\n",
    "        else:\n",
    "            # we do nothing\n",
    "            continue\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# we would need to calculate the current RSI, along with the previous RSI's to solidify the trend\n",
    "# how to get the live RSI?\n",
    "# we want to identify if the ticker is crossing a certain threshold in the RSI\n",
    "def calcRSI(ticker):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a collection of ticker names \n",
    "x_train_sell, y_train_sell = buildData_sell(names, 10)\n",
    "x_test_sell, y_test_sell = buildData_sell(test_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d85767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, for the classifier itself\n",
    "# using an SVM with a perceptron loss function\n",
    "\n",
    "# how to set the hyperparameters\n",
    "# need an intimate understanding of SVMS\n",
    "sell_classifier = SGDClassifier(loss='perceptron', learning_rate = 'adaptive')\n",
    "sell_classifier.fit(x_train_sell, y_train_sell)\n",
    "\n",
    "# to see the effectiveness of the model\n",
    "# we will predict on the test data\n",
    "\n",
    "\n",
    "# then, we use the classifier to make predictions pertaining to\n",
    "# 10-day information around our current positions, if any exist\n",
    "\n",
    "# if there is the possibility of a head/shoulders reversal\n",
    "# we sell, before it begins the true bearish trend\n",
    "\n",
    "# findSale \n",
    "# [String] -> [String]\n",
    "# parameters\n",
    "# myPositions: A list of the string ticker symbols of all of the users current, active positions\n",
    "# purpose: To determine if any of the actively held positions are in the course of a reversal\n",
    "def findSale(myPositions):\n",
    "    toSell = []\n",
    "    for position in myPositions:\n",
    "        toCheck = getData(position, 10)\n",
    "        if(sell_classifier.predict(toCheck) == 1):\n",
    "            toSell.append(position)\n",
    "    return toSell\n",
    "\n",
    "\n",
    "# makeSale\n",
    "# parameters\n",
    "# api: paper, or actual?\n",
    "def makeSale(api):\n",
    "    sell = findSale(myPositions)\n",
    "    i = 0\n",
    "    while(i < len(sell)):\n",
    "        \n",
    "        # first, find the amount of the current symbol held\n",
    "        size = api.get_position[sell[i]].qty\n",
    "        \n",
    "        api.submit_order(\n",
    "        symbol=findSale[i],\n",
    "        qty=size,\n",
    "        side='sell',\n",
    "        type='limit',\n",
    "        time_in_force='gtc')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef13c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20ff21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
